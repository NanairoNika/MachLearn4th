{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "exam_var1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKk2Vy39YOho",
        "colab_type": "text"
      },
      "source": [
        "3. Language model inference methods: properties, differences, cases of usage (without formulas, at least 2)  \n",
        "1 Свойства\n",
        "Большая часть из методов использует механизм Attention и LSTM для запоминания длинных цепочек из слов. Главная цель таким образом задать последовательность слов, чтобы из нее можно было вытянуть главную мысль\n",
        "\n",
        "2 Различия\n",
        "Различия могут быть в тренировке в частности в сравнивании эмбеддингов, в попытке извлечь главную мысль. Также есть методы основанные не на РНН а на Трансформерах\n",
        "3 Использование\n",
        "Q&A, paraphrasing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVDzpHht0pGl",
        "colab_type": "text"
      },
      "source": [
        "# Exam\n",
        "\n",
        "Develop a model for predicting review rating.  \n",
        "**Multiclass classification into 5 classes**  \n",
        "Score: **F1 with macro averaging**  \n",
        "You are forbidden to use test dataset for any kind of training.  \n",
        "Remember proper training pipeline.  \n",
        "If you are not using default params in the models, you have to use some validation scheme to justify them. \n",
        "\n",
        "Use `random_state` or `seed` params - your experiment must be reprodusible.\n",
        "\n",
        "\n",
        "### 1 baseline = 0.51\n",
        "### 2 baseline = 0.53\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nERd12ee0pGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "a76a5dbe-bda7-40e0-db39-859bb807fb3a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "!pip install pymorphy2\n",
        "import pymorphy2\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WGyzC8R0pGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "df_train[\"review\"] = df_train[\"review\"] + \" \" + df_train[\"title\"]\n",
        "df_train = df_train.drop(columns=[\"title\"])\n",
        "df_test[\"review\"] = df_test[\"review\"] + \" \" + df_test[\"title\"]\n",
        "df_test = df_test.drop(columns=[\"title\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnc7i4te2TLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph = pymorphy2.MorphAnalyzer()\n",
        "stopWords = stopwords.words('russian')\n",
        "def cleaning(text):\n",
        "    tokenized = []\n",
        "    words = word_tokenize(text)\n",
        "    for word in words:\n",
        "        p = morph.parse(word)[0]\n",
        "        tokenized.append(p.normal_form)\n",
        "    tokenized = [token for token in tokenized if token not in stopWords\\\n",
        "                and token != \" \" \\\n",
        "                and token != \"—\" \\\n",
        "                and token != \"«\" \\\n",
        "                and token != \"»\" \\\n",
        "                and token != \"..\" \\\n",
        "                and token.strip() not in punctuation]\n",
        "    return tokenized\n",
        "df_train_X = df_train['review'].apply(cleaning)\n",
        "df_test_X = df_test['review'].apply(cleaning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8inqOnL6ntn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_X = df_train_X.tolist()\n",
        "train_y = df_train[\"target\"].tolist()\n",
        "test_X = df_test_X.tolist()\n",
        "test_y = df_test[\"target\"].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdpH2U6wn-fU",
        "colab_type": "text"
      },
      "source": [
        "bm25 version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9DnXR0okXHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85db0dbc-224c-46e8-b49f-34106dd77c1e"
      },
      "source": [
        "from gensim.summarization.bm25 import get_bm25_weights\n",
        "for sent in test_X:\n",
        "    train_X.append(sent)\n",
        "print(len(train_X))\n",
        "result = get_bm25_weights(train_X, n_jobs=-1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1N7gvSVlFP0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b39c8bb3-1390-4233-f16d-b733a94aa29b"
      },
      "source": [
        "X_train = result[:48192,]\n",
        "X_test = result[48192:,]\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "LR = LogisticRegression(multi_class = 'multinomial')\n",
        "LR.fit(X_train, train_y)\n",
        "lrscore = f1_score(test_y, LR.predict(X_test), average = 'macro')\n",
        "print('BM25 LR test score: ', lrscore)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rank_bm25.BM25Okapi at 0x7f6a22a50ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQB2Qs07nzvk",
        "colab_type": "text"
      },
      "source": [
        "word2vec version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dqA-Yvb8rdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "095a9148-e6b2-4b62-e2d7-df7745b76ab0"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import Phrases\n",
        "bigram_transformer = Phrases(train_X)\n",
        "w2v = Word2Vec(min_count=1, window=3, size=100)\n",
        "w2v.build_vocab(bigram_transformer[train_X])\n",
        "w2v.train(train_X, total_examples=w2v.corpus_count, epochs=10)\n",
        "w2v.init_sims(replace=True)\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23243585, 32293390)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrAHYAr0Cz-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sent2vec (sent):\n",
        "  sentvec = np.zeros(100)\n",
        "  for word in sent:\n",
        "    if word in w2v.wv.vocab.keys():\n",
        "      sentvec += w2v.wv[word]\n",
        "  sentvec = sentvec/len(sent)\n",
        "  return sentvec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnZ1ie8wG9VL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train_X.apply(sent2vec).tolist()\n",
        "X_test = df_test_X.apply(sent2vec).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXxUjsPhEzvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a613e45-3677-43d4-dc4c-898ae9b9e9a6"
      },
      "source": [
        "neighbourscos = KNeighborsClassifier(n_neighbors=8, metric=\"cosine\")\n",
        "neighbourscos.fit(X_train, train_y)\n",
        "numb_of_neighbours = np.arange(1,50)\n",
        "gridparam = dict(n_neighbors = numb_of_neighbours)\n",
        "knncos = GridSearchCV(neighbourscos, gridparam, scoring = 'f1_macro')\n",
        "knncos.fit(X_train, train_y)\n",
        "print(knncos.best_params_['n_neighbors'])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr3K9okzUHBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd9b7bbe-17c6-49e6-df9e-0e6f253d3626"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "neighbourscos = KNeighborsClassifier(n_neighbors=knncos.best_params_['n_neighbors'], metric=\"cosine\")\n",
        "neighbourscos.fit(X_train, train_y)\n",
        "neighbourscos_test = f1_score(test_y, neighbourscos.predict(X_test), average = 'macro')\n",
        "print('knn cosine test score: ', neighbourscos_test)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "knn cosine test score:  0.43099439945424506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yzGM-gcn6OZ",
        "colab_type": "text"
      },
      "source": [
        "tfidf version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIdt8c8pd0JY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2c5e6d72-39e9-4987-ee7e-5462bdfeeaab"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "elmo_df_train = df_train['review'].tolist()\n",
        "elmo_df_test = df_test['review'].tolist()\n",
        "print(len(elmo_df_train), len(elmo_df_test))\n",
        "for item in elmo_df_test:\n",
        "    elmo_df_train.append(item)  \n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(elmo_df_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48192 5355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUL0o4BKgHqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "51e38d89-1baa-4571-d316-623ed64694e2"
      },
      "source": [
        "X_train = X[:48192,]\n",
        "X_test = X[48192:,]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5355, 45962)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc_V3usOhjBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "LR = LogisticRegression(multi_class = 'multinomial')\n",
        "LR.fit(X_train, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4jfxJKGiBG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d0a3f28-b27f-407a-f3a5-fc8b136968bc"
      },
      "source": [
        "lrscore = f1_score(test_y, LR.predict(X_test), average = 'macro')\n",
        "print('TFIDF LR test score: ', lrscore)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5180474110503306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}